{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predominant Mask - MusicBricks Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will guide you through some tools for performing spectral analysis and synthesis using the Essentia library (http://www.essentia.upf.edu). In this case we use a STFT analysis/synthesis workflow together with predominant pitch estimation with the goal to remove or soloing the predominant source. \n",
    "This algorithm uses a binary masking technique, modifying the magnitude values at the frequency bins in the spectrum that correspond to the harmonic series of the predominant pitch. It can be seen as a very primitive approach to 'source separation'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should first install the Essentia library with Python bindings. Installation instructions are detailed here: http://essentia.upf.edu/documentation/installing.html . \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to use essentia and numpy\n",
    "import essentia.standard as es\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters of the STFT workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm parameters\n",
    "framesize = 2048\n",
    "hopsize = 128 #  PredominantPitchMelodia requires a hopsize of 128\n",
    "samplerate = 44100.0\n",
    "attenuation_dB = 100\n",
    "maskbinwidth = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify input and output audio filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFilename = 'flamenco.wav'\n",
    "outputFilename = 'flamenco_stft.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of the audio sample [sec]: 14.229\n"
     ]
    }
   ],
   "source": [
    "# create an audio loader and import audio file\n",
    "audio = es.MonoLoader(filename=inputFilename, sampleRate=samplerate)()\n",
    "print(f\"Duration of the audio sample [sec]: {len(audio) / samplerate:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define algorithm chain for frame-by-frame process: \n",
    "FrameCutter -> Windowing -> FFT -> IFFT OverlapAdd -> AudioWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predominant pitch extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract predominant pitch\n",
    "# PitchMelodia takes the entire audio signal as input - no frame-wise processing is required here.\n",
    "pExt = es.PredominantPitchMelodia(frameSize=framesize, hopSize=hopsize, sampleRate=samplerate)\n",
    "pitch, pitchConf = pExt(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm workflow for harmonic mask using the STFT frame-by-frame\n",
    "fcut = es.FrameCutter(frameSize=framesize, hopSize=hopsize)\n",
    "w = es.Windowing(type=\"hann\")\n",
    "fft = es.FFT(size=framesize)\n",
    "hmask = es.HarmonicMask(sampleRate=samplerate, binWidth=maskbinwidth, attenuation=attenuation_dB)\n",
    "ifft = es.IFFT(size=framesize)\n",
    "overl = es.OverlapAdd(frameSize=framesize, hopSize=hopsize)\n",
    "awrite = es.MonoWriter(filename=outputFilename, sampleRate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop over all audio frames and store the processed audio sampels in the output array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioout = np.array(0) # initialize output array\n",
    "\n",
    "for idx, frame in enumerate(es.FrameGenerator(audio, frameSize=framesize, hopSize=hopsize)):\n",
    "     # STFT analysis\n",
    "    infft = fft(w(frame))\n",
    "    # get pitch of current frame\n",
    "    curpitch = pitch[idx]\n",
    "\n",
    "    # here we  apply the harmonic mask spectral transformations\n",
    "    outfft = hmask(infft, pitch[idx])\n",
    "\n",
    "    # STFT synthesis\n",
    "    out = overl(ifft(outfft))\n",
    "    audioout = np.append(audioout, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we write the processed audio array as a WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[wav @ 0x7f9e5a3cda00] Using AVStream.codec to pass codec parameters to muxers is deprecated, use AVStream.codecpar instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "In MonoWriter.compute: MonoWriter: error writing to audio file: Error while encoding audio frame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/xavierlizarraga/dev/python/repos/mir/my_fork/essentia/src/examples/python/musicbricks-tutorials/6-harmonic_mask.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xavierlizarraga/dev/python/repos/mir/my_fork/essentia/src/examples/python/musicbricks-tutorials/6-harmonic_mask.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# write audio output\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xavierlizarraga/dev/python/repos/mir/my_fork/essentia/src/examples/python/musicbricks-tutorials/6-harmonic_mask.ipynb#ch0000020?line=1'>2</a>\u001b[0m awrite(audioout\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32))\n",
      "File \u001b[0;32m~/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py:123\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=121'>122</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=122'>123</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py:104\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.compute\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=98'>99</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError cannot convert argument \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=99'>100</a>\u001b[0m               \u001b[39m%\u001b[39m(\u001b[39mstr\u001b[39m(_c\u001b[39m.\u001b[39mdetermineEdt(arg)), \u001b[39mstr\u001b[39m(goalType)))\n\u001b[1;32m    <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=101'>102</a>\u001b[0m     convertedArgs\u001b[39m.\u001b[39mappend(convertedData)\n\u001b[0;32m--> <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=103'>104</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__compute__(\u001b[39m*\u001b[39;49mconvertedArgs)\n\u001b[1;32m    <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=105'>106</a>\u001b[0m \u001b[39m# we have to make an exceptional case for YamlInput, because we need\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=106'>107</a>\u001b[0m \u001b[39m# to wrap the Pool that it outputs w/ our python Pool from common.py\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/xavierlizarraga/dev/python/repos/mir/test_essentia/env/lib/python3.9/site-packages/essentia/standard.py?line=107'>108</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mYamlInput\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPoolAggregator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSvmClassifier\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPCA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGaiaTransform\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mExtractor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTensorflowPredict\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: In MonoWriter.compute: MonoWriter: error writing to audio file: Error while encoding audio frame"
     ]
    }
   ],
   "source": [
    "# write audio output\n",
    "awrite(audioout.astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
